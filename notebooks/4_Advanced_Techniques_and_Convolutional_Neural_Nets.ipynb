{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4: Advanced Techniques and Convolutional Neural Nets",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9u8ULow9HAJVNk7OCSdvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allemanau/NUIT_tensorflow/blob/master/notebooks/4_Advanced_Techniques_and_Convolutional_Neural_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dug7p5MIpi5",
        "colab_type": "text"
      },
      "source": [
        "# __4: Convolutional Neural Nets__\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "In this notebook, we'll learn...\n",
        "- what a convolutional layer is, and why they work well for image data;\n",
        "- how to specify and fit a convnet in TensorFlow via the Keras API\n",
        "- use of data augmentation in image analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpXiKZW1pyEt",
        "colab_type": "text"
      },
      "source": [
        "Although our previous model seems to work pretty well, it regards pixel values as independent features, since we flattened the images. In reality, pixels are spatially related, and by flattening the data, we ignore more complex spatial information beyond pixel-to-pixel relationships that may improve predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw7I5CquQ9jY",
        "colab_type": "text"
      },
      "source": [
        "## __What are Convolutional Neural Nets?__\n",
        "\n",
        "The __convolutional neural network__ (or \"convnet\", or \"CNN\") uses alternating convolutional and max pooling layers to extract abstract features from image data.\n",
        "\n",
        "### __Convolutional layer__\n",
        "\n",
        "The workhorse in a CNN is the __convolutional layer__. The convolutional layer is composed of several __convolution filters__ (sometimes called \"kernels\"), which scan an image for certain shapes or features. A simplified example below illustrates how this works. When the \"eye kernel\" passes over an eye in the image, it activates, producing a large feature value:\n",
        "\n",
        "![](https://i.stack.imgur.com/9bi5k.gif)\n",
        "\n",
        "The kernel itself is a small matrix of weights, just a few pixels wide by a few pixels tall, and for color images, it has a depth equal to the number of color channels. It may seem from the example that kernels are complex, and thus need to be specified, but the weights for each kernel in the layer are actually learned by backpropagation.\n",
        "\n",
        "### Convolution operation\n",
        "\n",
        "Consider a  $3\\times3$ filter for an image:\n",
        "\n",
        "<img src=\"https://github.com/allemanau/NUIT_tensorflow/blob/master/images/conv_kernel.png?raw=1\">\n",
        "\n",
        "To get the convolution output, slide the filter over the image in each spot it fits, and take the weighted sum of the pixel values.\n",
        "\n",
        "<br>\n",
        "\n",
        "![](https://miro.medium.com/max/1070/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)\n",
        "\n",
        "<br>\n",
        "\n",
        "The convolutional output is a tensor of size\n",
        "\n",
        "<br>\n",
        "\\begin{equation*}\n",
        "\\text{(image width - filter width + 1)} \\times \\text{(image height - filter height + 1)} \\times (\\text{number of channels})\n",
        "\\end{equation*}\n",
        "<br>\n",
        "\n",
        "A layer is a collection of filters, each learning different features of the training images. Then, the size of the resulting convolutional layer will be\n",
        "\n",
        "<br>\n",
        "\\begin{equation*}\n",
        "\\text{(image width - filter width + 1)} \\times \\text{(image height - filter height + 1)} \\times (\\text{number of channels} = 1) \\times (\\text{number of filters})\n",
        "\\end{equation*}\n",
        "<br>\n",
        "\n",
        "Organizing convolutional layers is something of an art. In general, the key thing to remember is that __larger filter sizes extract generic global features__, while __smaller filter sizes extract complex local features__. Using smaller filter sizes also enables construction of a deeper network, potentially yielding performance gains at the cost of increased training and prediction time.\n",
        "\n",
        "### __Pooling__\n",
        "\n",
        "One problem with convolutional filters is that they activate precisely where the feature appears. A __pooling layer__ solves this problem by dividing a convolution filter into __patches__ and summarizing the content of the filter in that region. An extrapolation of the simple example above helps to illustrate how a pooling layer captures the same signature from a shifted version of the image:\n",
        "\n",
        "<br>\n",
        "\n",
        "![](https://i0.wp.com/www.thushv.com/wp-content/uploads/2018/05/pooling.gif?resize=1100%2C829)\n",
        "\n",
        "<br>\n",
        "\n",
        "This particular variant of pooling is called __max pooling__; it takes the largest activation value from the convolution patch to be the feature value in the pooling layer.\n",
        "\n",
        "### __Stacking convolutional and pooling layers to learn high level features__\n",
        "\n",
        "With the two primary tools of a CNN in hand, the general principle is to apply a convolutional layer, then a pooling layer, then another convolutional layer, and so on. We will do this for the MNIST data set in a moment.\n",
        "\n",
        "For novel problems, you can treat the layer sizes as parameters and tune them using a validation or cross-validation approach. Alternatively, you can adapt successful architectures others have built, [such as AlexNet](https://towardsdatascience.com/alexnet-the-architecture-that-challenged-cnns-e406d5297951), or even fine-tune the existing model for your problem via transfer learning (see the take-home exercise for more on this).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkwYwPEiRGS6",
        "colab_type": "text"
      },
      "source": [
        "Although there are a few aspects and tricks of convolutional layers left unexplained, we have enough in hand to apply 2D convolutional and max pooling layers to MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCKtMQRRG85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train_scl = x_train / 255.0\n",
        "x_test_scl = x_test / 255.0\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optim = 'adam'\n",
        "\n",
        "conv_model = Sequential()\n",
        "conv_model.add(Reshape((28, 28, 1)))\n",
        "conv_model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28,28)))\n",
        "conv_model.add(Conv2D(64, (3, 3)))\n",
        "conv_model.add(Activation('relu'))\n",
        "conv_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "conv_model.add(Dropout(0.2))\n",
        "conv_model.add(Flatten())\n",
        "conv_model.add(Dense(128))\n",
        "conv_model.add(Activation('relu'))\n",
        "conv_model.add(Dropout(0.5))\n",
        "conv_model.add(Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thpjieS8RMqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_model.compile(optimizer = optim,\n",
        "              loss = loss_fn,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                            patience=5, \n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "conv_model.fit(x_train_scl, \n",
        "          y_train, \n",
        "          #batch_size = 100,\n",
        "          epochs=50,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = [callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pARa4gW7RWG-",
        "colab_type": "text"
      },
      "source": [
        "Our convolutional model, along with the other improvements made along the way, demonstrates superior performance -- ~99% accurate! For reference, the best kernel on Kaggle for MNIST is 99.75% accurate (and is quite a bit more complicated)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_zVGNzdRW0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_model.evaluate(x_test_scl,\n",
        "               y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmtGtbheRd69",
        "colab_type": "text"
      },
      "source": [
        "Again, let's peek at a selection of mistakes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKC3VHsqRkH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predicted classes.\n",
        "preds = conv_model.predict_classes(x_test_scl)\n",
        "\n",
        "# Prepare a figure for subplotting.\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Select one random misclass for each digit in the data set.\n",
        "for i in range(10):\n",
        "    ind = np.random.choice(np.ndarray.flatten(np.argwhere((y_test == i) & (y_test != preds))))\n",
        "    actual = y_test[ind]\n",
        "    predicted = preds[ind]\n",
        "    plottable_image = np.reshape(x_test[ind], (28, 28))\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(plottable_image, cmap='gray_r')\n",
        "    plt.xlabel(\"Actual: \" + \"{}\".format(actual) + \", Predicted: \" + \"{}\".format(predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTUApur7mHqV",
        "colab_type": "text"
      },
      "source": [
        "## __Data Augmentation__\n",
        "\n",
        "An extremely useful trick to boost performance is to apply random __label-preserving transformations__ to create new training examples. These transformations include shifting and stretching images, adding small perturbations to the pixel values, and so on. This practice, called __data augmentation__, improves the ability of the model to generalize to unseen examples exhibiting these small changes. Keras provides an easy-to-use data augmentation toolkit:\n",
        "\n",
        "\\<STILL UNDER CONSTRUCTION\\>"
      ]
    }
  ]
}