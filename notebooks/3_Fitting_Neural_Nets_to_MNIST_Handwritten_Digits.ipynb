{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3: Fitting Neural Nets to MNIST Handwritten Digits",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh8lE2lOAaPEEuCGQKOeQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allemanau/NUIT_tensorflow/blob/master/notebooks/3_Fitting_Neural_Nets_to_MNIST_Handwritten_Digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfNw9Qq9nUrX",
        "colab_type": "text"
      },
      "source": [
        "# __3: Fitting Neural Nets to MNIST Handwritten Digits__\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "In this notebook, we'll learn...\n",
        "- how to fit a neural network to flat data and best practices for preprocessing\n",
        "- how to use callbacks and validation sets to stop training and prevent overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmYw-7WvD2LG",
        "colab_type": "text"
      },
      "source": [
        "## Import modules\n",
        "As before, let's start by importing the necessary Python modules, including `tensorflow`, `numpy`, and `matplotlib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxfmfttD2LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import latest TensorFlow 2 release, NumPy, and matplotlib\n",
        "# Until 2.x is the default in Colab, stipulates that we want to load the latest version of TensorFlow 2.0, not 1.x.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, ActivityRegularization, Input, Reshape, Flatten, Conv2D\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Changing this option from the default of 75 characters will allow arrays to print entire rows.\n",
        "np.set_printoptions(linewidth=np.inf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1hAbkjFD2LQ",
        "colab_type": "text"
      },
      "source": [
        "## Importing MNIST data\n",
        "\n",
        "For this part of the workshop we'll use the MNIST handwriting data set. You might've heard of this dataset -- it's a benchmark for deep learning and is easily accessible through Tensorflow.\n",
        "\n",
        "The dataset contains $60,000$ examples for training and $10,000$ examples for testing. Each image is $28\\times 28$ pixels, each with a greyscale value from 0 to 255 (0 is black, 255 is white). Below, see some examples; for more on MNIST, see Yann LeCun's [website](http://yann.lecun.com/exdb/mnist/). \n",
        "\n",
        "<br>\n",
        "<img src=\"https://github.com/allemanau/NUIT_tensorflow/blob/master/images/mnist.jpg?raw=1\">\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PxFTshX80pt",
        "colab_type": "text"
      },
      "source": [
        "### Data dimension\n",
        "Here, we specify the dimensions of the images which will be used in several places in the code below. Defining these variables makes it easier (compared with using hard-coded number all throughout the code) to modify them later. Ideally these would be inferred from the data that has been read, but here we will just write the numbers.\n",
        "\n",
        "It's important to note that in a linear model, we have to flatten the input images into a vector. Here, each of the $28\\times28$ images are flattened into a $1\\times784$ vector. \n",
        "\n",
        "### 1.3. Load the data and display the sizes\n",
        "Because it is so often used to test network architecture, built-in functions are provided to load the data set into TensorFlow. We can use a built-in function to load the `train` and `test` splits easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SBLjgDDD2Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, raw_y_train), (x_test, raw_y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYbX3TykdWns",
        "colab_type": "text"
      },
      "source": [
        "To get a better sense of the data, let's checkout the shapes of the loaded arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GCSmo2QdXZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('x_train:\\t{}'.format(x_train.shape))\n",
        "print('y_train:\\t{}'.format(raw_y_train.shape))\n",
        "print('x_test:\\t\\t{}'.format(x_test.shape))\n",
        "print('y_test:\\t\\t{}'.format(raw_y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B9s-IcKbDul",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at a raw training example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BysFAkRfbD9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enables the console to print entire rows of the array.\n",
        "print(\"{}\".format(x_train[2020]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7MlELFiWsqE",
        "colab_type": "text"
      },
      "source": [
        "Although there are model configurations that don't require one-hot encoding of the outcome variable, it's good practice to stick with a consistent coding scheme unless you are comfortable with optimization options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn8qh5ozWtkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hot encode classes\n",
        "y_train = to_categorical(raw_y_train, num_classes = 10)\n",
        "y_test = to_categorical(raw_y_test, num_classes = 10)\n",
        "\n",
        "print(\"First three entries of raw y_train:\\n {}\\n\".format(raw_y_train[0:3]))\n",
        "print(\"First three rows of one-hot y_train:\\n {}\".format(y_train[0:3,]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SObeZPn9rQP6",
        "colab_type": "text"
      },
      "source": [
        "### Plot a few examples\n",
        "\n",
        "Let's take a quick look at a sample of the handwritten digits in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZqFFa6qrPnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize = (12, 6))\n",
        "\n",
        "for i in range(10):\n",
        "    ind = np.random.choice(np.ndarray.flatten(np.argwhere(raw_y_train == i)))\n",
        "    plottable_image = np.reshape(x_train[ind], (28, 28))\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(plottable_image, cmap='gray_r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpfV2KRBD2Lx",
        "colab_type": "text"
      },
      "source": [
        "## __Hyperparameters__\n",
        "\n",
        "In the last notebook, we talked a bit about specifying the number of epochs to train for -- nothing formal, just recognition of the fact that 500 epochs was too many. In reality, this is just one of many hyperparameters we can tune to improve performance and convergence, or reduce training time and memory usage.\n",
        "\n",
        "- _Length of model fitting routine_\n",
        "  - __epoch__: one forward pass and one backward pass of __all__ the training examples, regulated by the `epochs` parameter. (Each progress bar you see in the output of `fit()`)\n",
        "  - __batch size__: the number of training examples in one forward/backward pass, regulated by the `batch_size` parameter. The higher the batch size, the more memory space you'll need, and the less often the model's parameters will update.\n",
        "  - __iteration__: one forward pass and one backward pass of __one batch of images__ the training examples. The number of iterations in one epoch is related to the batch size and number of training examples as \n",
        "\n",
        "  \\begin{equation*}\n",
        "  \\text{iterations} = \\text{ceiling}(\\text{training examples}/\\text{batch size})\n",
        "  \\end{equation*}\n",
        "\n",
        "- _Rate of model weight adjustment_\n",
        "  - __learning rate__: controls the rate at which model parameters are adjusted, regulated by the `learning_rate` parameter. Lower rates mean the model trains slower, but with potentially improved convergence. Higher rates mean faster training but can cause convergence issues.\n",
        "  - __optimizer__: some optimizers are better for certain applications. Some are just better than others, period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyT0zD6eD2Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global settings\n",
        "loss_fn = 'categorical_crossentropy'\n",
        "optim = 'adam'\n",
        "batch_size = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9gJHdBdD2MN",
        "colab_type": "text"
      },
      "source": [
        "### Specify a network architecture\n",
        "\n",
        "Below is the neural network architecture we will use today for classifying MNIST digits.\n",
        "\n",
        "<img src=\"https://github.com/allemanau/NUIT_tensorflow/blob/master/images/network_architecture.png?raw=1\">\n",
        "\n",
        "Using the layering syntax from the previous notebook, let's build this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgOV-i-xSlqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basic_model = Sequential()\n",
        "basic_model.add(Flatten(input_shape = (28,28)))\n",
        "basic_model.add(Dense(units = 128))\n",
        "basic_model.add(Activation(activation = 'relu'))\n",
        "basic_model.add(Dense(units = 10))\n",
        "basic_model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "# Plot our model.\n",
        "plot_model(basic_model, show_shapes = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jKKRSXR3zJ-",
        "colab_type": "text"
      },
      "source": [
        "## Compile and fit the model\n",
        "\n",
        "The model's architecture is specified and has been instantiated as an object. Now, we need to __compile__ and __fit__ the model to data. Along the way, there are still several choices to make: which method should be used to optimize the network, by what loss function will we measure our success, and which progress metrics should be reported?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owRUoN1NTaQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In general, the ADAM optimizer does a good job. For larger data sets, \n",
        "# stochastic gradient descent can be a better choice.\n",
        "basic_model.compile(optimizer = optim,\n",
        "                    loss = loss_fn,\n",
        "                    metrics = ['accuracy'])\n",
        "\n",
        "history = basic_model.fit(x_train, \n",
        "                y_train, \n",
        "                batch_size = batch_size,\n",
        "                epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc-tVkt9uF-L",
        "colab_type": "text"
      },
      "source": [
        "Evaluation on the test set indicates the model is about 95% accurate -- not bad for a first pass on a balanced multi-class prediction problem with only 10 epochs of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqZuovjuQXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = basic_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\")\n",
        "print(\"{}%\".format(np.round(100*score[1], 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xst2cKfuXWs",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a few misclassified examples. Although there'll be variation due to the random selection of examples, there's a mixed bag of understandable confusion and bad misses here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPToYLeuhPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predicted classes.\n",
        "preds = basic_model.predict_classes(x_test)\n",
        "\n",
        "# Prepare a figure for subplotting.\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Select one random misclass for each digit in the data set.\n",
        "for i in range(10):\n",
        "    ind = np.random.choice(np.ndarray.flatten(np.argwhere((raw_y_test == i) & (raw_y_test != preds))))\n",
        "    actual = raw_y_test[ind]\n",
        "    predicted = preds[ind]\n",
        "    plottable_image = np.reshape(x_test[ind], (28, 28))\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(plottable_image, cmap='gray_r')\n",
        "    plt.xlabel(\"Actual: \" + \"{}\".format(actual) + \", Predicted: \" + \"{}\".format(predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt_xUVoA7VGR",
        "colab_type": "text"
      },
      "source": [
        "### Importance of scaling features\n",
        "\n",
        "Unscaled features often result in numerical instability in the gradient during the fitting process. Let's rescale the features to lie between 0 and 1 and refit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPDJtXCg7ak3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General rescaling: (x - min(x))/(max(x) - min(x))\n",
        "# In this dataset, grayscale values lie between 0 and 255. \n",
        "# Thus, rescaling is easy:\n",
        "x_train_scl = x_train / 255.0\n",
        "x_test_scl = x_test / 255.0\n",
        "\n",
        "scaled_model = Sequential()\n",
        "scaled_model.add(Flatten(input_shape = (28,28)))\n",
        "scaled_model.add(Dense(units = 128))\n",
        "scaled_model.add(Activation(activation = 'relu'))\n",
        "scaled_model.add(Dense(units = 10))\n",
        "scaled_model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "scaled_model.compile(optimizer = 'adam',\n",
        "              loss = loss_fn,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = scaled_model.fit(x_train_scl, \n",
        "          y_train, \n",
        "          batch_size = batch_size,\n",
        "          epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Yfzc7ez01I",
        "colab_type": "text"
      },
      "source": [
        "First thing to note: the model converged much faster. The training accuracy by the second or third epoch beats the model trained on unscaled data after 10 epochs.\n",
        "\n",
        "The second important thing to note is that the accuracy against the training data is obviously much higher, although we should be careful using this metric because it doesn't generalize meaningfully. Evaluating the model against rescaled test data demonstrates this improvement translates to unseen examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3hLapl-z7VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = scaled_model.evaluate(x_test_scl, y_test, verbose=0)\n",
        "print(\"Test accuracy:\")\n",
        "print(\"{}%\".format(np.round(100*score[1], 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgJhDxcQ0A57",
        "colab_type": "text"
      },
      "source": [
        "Taking a peek at misclasses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c_coMWU0P16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predicted classes.\n",
        "preds = scaled_model.predict_classes(x_test)\n",
        "\n",
        "# Prepare a figure for subplotting.\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Select one random misclass for each digit in the data set.\n",
        "for i in range(10):\n",
        "    ind = np.random.choice(np.ndarray.flatten(np.argwhere((raw_y_test == i) & (raw_y_test != preds))))\n",
        "    actual = raw_y_test[ind]\n",
        "    predicted = preds[ind]\n",
        "    plottable_image = np.reshape(x_test[ind], (28, 28))\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.imshow(plottable_image, cmap='gray_r')\n",
        "    plt.xlabel(\"Actual: \" + \"{}\".format(actual) + \", Predicted: \" + \"{}\".format(predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwuC-5kJ9EcT",
        "colab_type": "text"
      },
      "source": [
        "## __Measuring progress using a validation set__\n",
        "\n",
        "In recognition of the fact that overfitting, that most insidious foe of deep neural networks, can easily happen on complicated problems like this, consider for a moment that we can generally improve training accuracy by increasing the number of epochs. So how do we choose when to stop?\n",
        "\n",
        "\n",
        "This is a job for a validation data set. Holding a small (5-10%) sample of our training data out of the training process enables us to test the out-of-sample accuracy of the model at each epoch. The idea here is to stop training the model when the validation metric starts moving the opposite direction of the training metric. In the case of accuracy, this would mean the training process should stop when the validation accuracy starts decreasing, and vice versa in the case of validation loss.\n",
        "\n",
        "\n",
        "#### Model callbacks\n",
        "\n",
        "In Tensorflow, a __callback__ is a utility called during the training process. They have various purposes, from logging histories to halting the fitting process (see the Tensorflow docs for a [full list of callback options](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)). One useful callback forces the training process to stop early if a validation metric isn't improving, which we'll use here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Op3JGJ9A_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_model = Sequential()\n",
        "valid_model.add(Flatten(input_shape=(28, 28)))\n",
        "valid_model.add(Dense(128))\n",
        "valid_model.add(Activation(activation = 'relu'))\n",
        "valid_model.add(Dense(10))\n",
        "valid_model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "valid_model.compile(optimizer = optim,\n",
        "              loss = loss_fn,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Use a callback to stop the model training once \"patience\" epochs have passed\n",
        "# without improvement in the validation accuracy. In addition, request\n",
        "# that the weights from the best iteration are restored.\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                            patience=10,\n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "# Add our callback to the model. Several callbacks could be specified\n",
        "# in a single list!\n",
        "history = valid_model.fit(x_train_scl, \n",
        "          y_train, \n",
        "          batch_size = batch_size,\n",
        "          epochs = 50,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = [callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9DIp3dh-m0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wze3NmCi5mzW",
        "colab_type": "text"
      },
      "source": [
        "As before, we evaluate our model and should discover marginal improvement using early stopping. Depending on the random components of the fitting process, you may be unlucky enough to see no improvement. (In this case, imagine if we had instead trained the model for 100 epochs, or 500 epochs. Alternatively, check with your neighbors and see whether they experienced improvement.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpZlTcLP5t3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = valid_model.evaluate(x_test_scl, y_test, verbose=0)\n",
        "print(\"Test accuracy:\")\n",
        "print(\"{}%\".format(np.round(100*score[1], 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNrc8s6wpFOv",
        "colab_type": "text"
      },
      "source": [
        "## __Dropout__\n",
        "\n",
        "In spite of our efforts to control overfitting with a validation set, we're hitting perfect classification accuracy on the training data, which suggests overfitting. Let's try to use a `Dropout` layer to fix this small problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHS9dPZpa-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_model = Sequential()\n",
        "dropout_model.add(Flatten(input_shape = (28, 28)))\n",
        "dropout_model.add(Dense(128))\n",
        "dropout_model.add(Activation(activation = 'relu'))\n",
        "dropout_model.add(Dropout(rate = 0.2))\n",
        "dropout_model.add(Dense(10))\n",
        "dropout_model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "dropout_model.compile(optimizer = optim,\n",
        "              loss = loss_fn,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                            patience = 10,\n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "history = dropout_model.fit(x_train_scl, \n",
        "          y_train, \n",
        "          batch_size = batch_size,\n",
        "          epochs = 50,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = [callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-LvHRWmp5kT",
        "colab_type": "text"
      },
      "source": [
        "Evaluating accuracy on the test set, most of you should see a small improvement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyK_MmIfqBNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = dropout_model.evaluate(x_test_scl, y_test, verbose=0)\n",
        "print(\"Test accuracy:\")\n",
        "print(\"{}%\".format(np.round(100*score[1], 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddpr3-PhxHuB",
        "colab_type": "text"
      },
      "source": [
        "## __Summarizing incremental improvements__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJqzOEGvr8iR",
        "colab_type": "text"
      },
      "source": [
        "Even if you didn't see the improvements in specific cases, maybe a small statistical anecdote will convince you of the incremental improvements we made. Each of the nets we fit above were refit 10 times for 50 epochs or whenever the stopping criterion was met, and the test accuracy is reported using boxplots below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nernUk_2sbqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experimental results, 10 fits each, 50 epochs or whenever a callback stops training.\n",
        "basic = [95.19, 95.35, 95.76, 95.15, 94.69, 95.18, 95.36, 95.04, 95.41, 95.17]\n",
        "scale = [97.75, 98.07, 97.61, 97.93, 97.84, 97.93, 97.81, 97.86, 98.11, 97.98]\n",
        "valid = [97.89, 97.98, 97.88, 97.87, 98.05, 98.10, 97.96, 97.73, 98.05, 98.06]\n",
        "dropout = [98.06, 98.12, 98.15, 97.95, 98.15, 98.18, 98.09, 98.08, 98.07, 98.23]\n",
        "\n",
        "# Construct pandas DataFrame from results.\n",
        "df = pd.DataFrame({'Model Type' : [\"Basic\"]*10 + [\"Scaled\"]*10 + [\"Validation\"]*10 + [\"Dropout\"]*10,\n",
        "        'Test Accuracy (%)' : basic + scale + valid + dropout})\n",
        "df['Model Type'] = df['Model Type'].astype(pd.api.types.CategoricalDtype(categories = [\"Basic\", \"Scaled\", \"Validation\", \"Dropout\"], ordered=True))\n",
        "\n",
        "# Draw boxplots of test performance by model type.\n",
        "sns.set(font_scale = 2)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "sns.boxplot(x = df['Model Type'], y = df['Test Accuracy (%)'], )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtBYJb-7k8uS",
        "colab_type": "text"
      },
      "source": [
        "## __Exercise: can you improve on the dropout model?__ (~10 min)\n",
        "\n",
        "Can you improve on the dropout model using only the layer types we've used so far? Keep track of your best test accuracy and the changes you made to get it. We'll reconvene to see who was able to do the best.\n",
        "\n",
        "__Tips__: try making the network more complex. Add a layer or two and/or increase the number of hidden nodes. Remember that complexity can lead to overfitting, so make use of dropout!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyi7m3Tdk88W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ex_model = Sequential()\n",
        "ex_model.add(Flatten(input_shape=(28, 28)))\n",
        "ex_model.add(Dense(128))\n",
        "ex_model.add(Activation(activation = 'relu'))\n",
        "ex_model.add(Dropout(rate = 0.2))\n",
        "ex_model.add(Dense(10))\n",
        "ex_model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "ex_model.compile(optimizer = optim,\n",
        "              loss = loss_fn,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Use a callback to stop the model training once \"patience\" epochs have passed\n",
        "# without improvement in the validation accuracy. In addition, request\n",
        "# that the weights from the best iteration are restored.\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', \n",
        "                                            patience = 10,\n",
        "                                            restore_best_weights = True)\n",
        "\n",
        "# Add our callback to the model. Several callbacks could be specified\n",
        "# in a single list!\n",
        "history = ex_model.fit(x_train_scl, \n",
        "          y_train, \n",
        "          batch_size = batch_size,\n",
        "          epochs = 50,\n",
        "          validation_split = 0.1,\n",
        "          callbacks = [callback])\n",
        "\n",
        "score = ex_model.evaluate(x_test_scl, y_test, verbose=0)\n",
        "print(\"Test accuracy:\")\n",
        "print(\"{}%\".format(np.round(100*score[1], 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ehrTNyDmfhn",
        "colab_type": "text"
      },
      "source": [
        "## __Review__\n",
        "\n",
        "Concepts to know:\n",
        "\n",
        "- __Network architecture__\n",
        "  - Expressing a model in TensorFlow using a network diagram\n",
        "- __Best practices__\n",
        "  - Feature scaling (can also normalize)\n",
        "  - One-hot encoding\n",
        "- __Validation splits__\n",
        "  - Using callbacks to stop model training early\n",
        "- __Dropout__\n",
        "  - What is the purpose of this layer?\n",
        "  - How does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWl9mYKM0HAg",
        "colab_type": "text"
      },
      "source": [
        "## __Next__: boosting accuracy via convolutional layers."
      ]
    }
  ]
}